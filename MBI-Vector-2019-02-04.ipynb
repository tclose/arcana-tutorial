{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, math, os.path, shutil, errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up dummy project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test project with dummy data\n",
    "NUM_SUBJECTS = 3\n",
    "NUM_VISITS = 2\n",
    "\n",
    "HEIGHT_MEAN = 1700\n",
    "HEIGHT_STD = 150\n",
    "WEIGHT_MEAN = 70\n",
    "WEIGHT_STD = 25\n",
    "HEAD_CIRC_MEAN = 570\n",
    "HEAD_CIRC_STD = 30\n",
    "\n",
    "subjects = ['subject{}'.format(i) for i in range(NUM_SUBJECTS)]\n",
    "visits = ['visit{}'.format(i) for i in range(NUM_VISITS)]\n",
    "\n",
    "project_dir = os.path.join(os.environ['HOME'], 'Desktop', 'arcana_tutorial')\n",
    "# Clean old directory\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "os.mkdir(project_dir)\n",
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        session_dir = os.path.join(project_dir, subj, visit)\n",
    "        try:\n",
    "            os.makedirs(session_dir)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "        with open(os.path.join(session_dir, 'metrics.txt'), 'w') as f:\n",
    "            f.write('height {}\\n'.format(numpy.random.randn() * HEIGHT_STD + HEIGHT_MEAN))\n",
    "            f.write('weight {}\\n'.format(numpy.random.randn() * WEIGHT_STD + WEIGHT_MEAN))\n",
    "            f.write('head_circ {}\\n'.format(numpy.random.randn() * HEAD_CIRC_STD + HEAD_CIRC_MEAN))\n",
    "print(\"Created project in {} directory\".format(project_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interface for 'grep' tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, File, isdefined,\n",
    "    CommandLineInputSpec, CommandLine)\n",
    "\n",
    "class GrepInputSpec(CommandLineInputSpec):\n",
    "    match_str = traits.Str(argstr='-e %s', position=0,\n",
    "                           desc=\"The string to search for\")\n",
    "    in_file = File(argstr='%s', position=1,\n",
    "                   desc=\"The file to search\")\n",
    "    out_file = File(genfile=True, argstr='> %s', position=2,\n",
    "                    desc=(\"The file to contain the search results\"))\n",
    "\n",
    "\n",
    "class GrepOutputSpec(TraitedSpec):\n",
    "    out_file = File(exists=True, desc=\"The search results\")\n",
    "\n",
    "\n",
    "class Grep(CommandLine):\n",
    "    \"\"\"Creates a zip archive from a given folder\"\"\"\n",
    "\n",
    "    _cmd = 'grep'\n",
    "    input_spec = GrepInputSpec\n",
    "    output_spec = GrepOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_file'] = self._gen_filename('out_file')\n",
    "        return outputs\n",
    "\n",
    "    def _gen_filename(self, name):\n",
    "        if name == 'out_file':\n",
    "            if isdefined(self.inputs.out_file):\n",
    "                fname = self.inputs.out_file\n",
    "            else:\n",
    "                fname = os.path.join(os.getcwd(), 'search_results.txt')\n",
    "        else:\n",
    "            assert False\n",
    "        return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grep = Grep()\n",
    "grep.inputs.in_file = os.path.join(project_dir, 'subject0', 'visit0', 'metrics.txt')\n",
    "grep.inputs.match_str = 'height'\n",
    "results = grep.run()\n",
    "print(results.outputs)\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        grep = Grep()\n",
    "        grep.inputs.match_str = 'height'\n",
    "        grep.inputs.in_file = os.path.join(project_dir, subj, visit, 'metrics.txt')\n",
    "        grep.inputs.out_file = os.path.join(project_dir, subj, visit, 'grep.txt')\n",
    "        result = grep.run()\n",
    "        print('Processed {}'.format(result.outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interface for 'awk' tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, File, isdefined,\n",
    "    CommandLineInputSpec, CommandLine)\n",
    "\n",
    "class AwkInputSpec(CommandLineInputSpec):\n",
    "    format_str = traits.Str(argstr=\"'%s'\", position=0,\n",
    "                            desc=\"The string to search for\")\n",
    "    in_file = File(argstr='%s', position=1,\n",
    "                   desc=\"The file to parse\")\n",
    "    out_file = File(genfile=True, argstr='> %s', position=2,\n",
    "                    desc=(\"The file to contain the parsed results\"))\n",
    "\n",
    "\n",
    "class AwkOutputSpec(TraitedSpec):\n",
    "    out_file = File(exists=True, desc=\"The parsed results\")\n",
    "\n",
    "\n",
    "class Awk(CommandLine):\n",
    "    \"\"\"Creates a zip archive from a given folder\"\"\"\n",
    "\n",
    "    _cmd = 'awk'\n",
    "    input_spec = AwkInputSpec\n",
    "    output_spec = AwkOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_file'] = self._gen_filename('out_file')\n",
    "        return outputs\n",
    "\n",
    "    def _gen_filename(self, name):\n",
    "        if name == 'out_file':\n",
    "            if isdefined(self.inputs.out_file):\n",
    "                fname = self.inputs.out_file\n",
    "            else:\n",
    "                fname = os.path.join(os.getcwd(), 'awk_results.txt')\n",
    "        else:\n",
    "            assert False\n",
    "        return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        awk = Awk()\n",
    "        awk.inputs.format_str = '{print $2}'\n",
    "        awk.inputs.in_file = os.path.join(project_dir, subj, visit, 'grep.txt')\n",
    "        awk.inputs.out_file = os.path.join(project_dir, subj, visit, 'awk.txt')\n",
    "        result = awk.run()\n",
    "        print('Processed {}'.format(result.outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Matlab interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import traits\n",
    "from nipype.interfaces.base import TraitedSpec\n",
    "from nipype.interfaces.matlab import MatlabCommand, MatlabInputSpec\n",
    "\n",
    "\n",
    "class HelloWorldInputSpec(MatlabInputSpec):\n",
    "    name = traits.Str(mandatory=True,\n",
    "                      desc='Name of person to say hello to')\n",
    "\n",
    "\n",
    "class HelloWorldOutputSpec(TraitedSpec):\n",
    "    matlab_output = traits.Str()\n",
    "\n",
    "\n",
    "class HelloWorld(MatlabCommand):\n",
    "    input_spec = HelloWorldInputSpec\n",
    "    output_spec = HelloWorldOutputSpec\n",
    "\n",
    "    def _my_script(self):\n",
    "        \"\"\"This is where you implement your script\"\"\"\n",
    "        script = \"\"\"\n",
    "        disp('Hello {}')\n",
    "        \"\"\".format(self.inputs.name)\n",
    "        return script\n",
    "\n",
    "    def run(self, **inputs):\n",
    "        # Inject your script\n",
    "        self.inputs.script = self._my_script()\n",
    "        results = super(MatlabCommand, self).run(**inputs)\n",
    "        stdout = results.runtime.stdout\n",
    "        # Attach stdout to outputs to access matlab results\n",
    "        results.outputs.matlab_output = stdout\n",
    "        return results\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = HelloWorld()\n",
    "hello.inputs.name = 'Tom'\n",
    "out = hello.run()\n",
    "print(out.outputs.matlab_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility 'concat' Python interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, BaseInterface, File, isdefined, InputMultiPath)\n",
    "\n",
    "class ConcatFloatsInputSpec(TraitedSpec):\n",
    "    in_files = InputMultiPath(desc='file name')\n",
    "\n",
    "\n",
    "class ConcatFloatsOutputSpec(TraitedSpec):\n",
    "    out_list = traits.List(traits.Float, desc='input floats')\n",
    "\n",
    "\n",
    "class ConcatFloats(BaseInterface):\n",
    "    \"\"\"Joins values from a list of files into a single list\"\"\"\n",
    "\n",
    "    input_spec = ConcatFloatsInputSpec\n",
    "    output_spec = ConcatFloatsOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        out_list = []\n",
    "        for path in self.inputs.in_files:\n",
    "            with open(path) as f:\n",
    "                val = float(f.read())\n",
    "                out_list.append(val)\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_list'] = out_list\n",
    "        return outputs\n",
    "\n",
    "    def _run_interface(self, runtime):\n",
    "        # Do nothing\n",
    "        return runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python interface using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, BaseInterface)\n",
    "\n",
    "class ExtractMetricsInputSpec(TraitedSpec):\n",
    "    in_list = traits.List(traits.Float, desc='input floats')\n",
    "\n",
    "\n",
    "class ExtractMetricsOutputSpec(TraitedSpec):\n",
    "    std = traits.Float(desc=\"The standard deviation\")\n",
    "    avg = traits.Float(desc=\"The average\")\n",
    "\n",
    "\n",
    "class ExtractMetrics(BaseInterface):\n",
    "    \"\"\"Joins values from a list of files into a single list\"\"\"\n",
    "\n",
    "    input_spec = ExtractMetricsInputSpec\n",
    "    output_spec = ExtractMetricsOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        values = self.inputs.in_list\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['std'] = numpy.std(values)\n",
    "        outputs['avg'] = numpy.average(values)\n",
    "        return outputs\n",
    "\n",
    "    def _run_interface(self, runtime):\n",
    "        # Do nothing\n",
    "        return runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual run concatenation and metric extraction over project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = []\n",
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        in_files.append(os.path.join(project_dir, subj, visit, 'awk.txt'))\n",
    "\n",
    "concat_floats = ConcatFloats()\n",
    "concat_floats.inputs.in_files = in_files\n",
    "result = concat_floats.run()\n",
    "print('Output list {}'.format(result.outputs.out_list))\n",
    "\n",
    "extract_metrics = ExtractMetrics()\n",
    "extract_metrics.inputs.in_list = result.outputs.out_list\n",
    "result = extract_metrics.run()\n",
    "print('Average: {}'.format(result.outputs.avg))\n",
    "print('Std.: {}'.format(result.outputs.std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiPype workflow for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.pipeline import engine as pe  # pypeline engine\n",
    "from nipype.interfaces.utility import IdentityInterface, Merge\n",
    "from nipype.interfaces.io import DataGrabber\n",
    "\n",
    "# Create workflow\n",
    "workflow = pe.Workflow(name='my_workflow')\n",
    "\n",
    "# Create subjects iterator\n",
    "subject_iterator = pe.Node(IdentityInterface(['subject_id']),\n",
    "                           name='subject_iterator')\n",
    "workflow.add_nodes([subject_iterator])\n",
    "subject_iterator.iterables = ('subject_id', subjects)\n",
    "\n",
    "# Create visits iterator\n",
    "visit_iterator = pe.Node(IdentityInterface(['visit_id']),\n",
    "                         name='visit_iterator')\n",
    "workflow.add_nodes([visit_iterator])\n",
    "visit_iterator.iterables = ('visit_id', visits)\n",
    "\n",
    "# Create data grabber\n",
    "datasource = pe.Node(\n",
    "    interface=DataGrabber(\n",
    "        infields=['subject_id', 'visit_id'], outfields=['metrics']),\n",
    "    name='datasource')\n",
    "datasource.inputs.template = \"%s/%s/metrics.txt\"\n",
    "datasource.inputs.base_directory = project_dir\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.template_args = {'metrics': [['subject_id', 'visit_id']]}\n",
    "workflow.add_nodes([datasource])\n",
    "\n",
    "# Create grep node\n",
    "grep = pe.Node(Grep(), name='grep')\n",
    "grep.inputs.match_str = 'height'\n",
    "workflow.add_nodes([grep])\n",
    "\n",
    "# Create awk node\n",
    "awk = pe.Node(Awk(), name='awk')\n",
    "awk.inputs.format_str = '{print $2}'\n",
    "workflow.add_nodes([awk])\n",
    "\n",
    "# Merge subject and visit iterators\n",
    "merge_visits = pe.JoinNode(Merge(1), name='merge_visits', joinfield='in1',\n",
    "                           joinsource='visit_iterator')\n",
    "merge_subjects = pe.JoinNode(Merge(1), name='merge_subjects', joinfield='in1',\n",
    "                    joinsource='subject_iterator')\n",
    "merge_subjects.inputs.ravel_inputs = True\n",
    "workflow.add_nodes([merge_subjects, merge_visits])\n",
    "                                            \n",
    "# Concat floats node\n",
    "concat = pe.Node(ConcatFloats(), name='concat')\n",
    "workflow.add_nodes([concat])\n",
    "                                            \n",
    "# Extract metrics Node\n",
    "extract_metrics = pe.Node(ExtractMetrics(), name='extract')\n",
    "workflow.add_nodes([extract_metrics])\n",
    "                                            \n",
    "# Connect Nodes together                          \n",
    "workflow.connect(subject_iterator, 'subject_id', datasource, 'subject_id')\n",
    "workflow.connect(visit_iterator, 'visit_id', datasource, 'visit_id')\n",
    "workflow.connect(datasource, 'metrics', grep, 'in_file')\n",
    "workflow.connect(grep, 'out_file', awk, 'in_file')\n",
    "workflow.connect(awk, 'out_file', merge_visits, 'in1')\n",
    "workflow.connect(merge_visits, 'out', merge_subjects, 'in1')\n",
    "workflow.connect(merge_subjects, 'out', concat, 'in_files')\n",
    "workflow.connect(concat, 'out_list', extract_metrics, 'in_list')\n",
    "             \n",
    "\n",
    "# Run workflow\n",
    "workflow.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.write_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('graph.png')\n",
    "fig = plt.figure()\n",
    "plt.imshow(img)\n",
    "fig.set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Arcana Study class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Study class, defining its constituent data and option specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcana\n",
    "from arcana import (Study, StudyMetaClass, ParameterSpec, AcquiredFilesetSpec,\n",
    "                    FilesetSpec, FieldSpec)\n",
    "from arcana.data.file_format.standard import text_format\n",
    "\n",
    "\n",
    "class MyStudy(Study, metaclass=StudyMetaClass): \n",
    "    \n",
    "    add_data_specs = [\n",
    "        AcquiredFilesetSpec('body_metrics', text_format),\n",
    "        FilesetSpec('selected_metric', text_format, 'extract_metrics_pipeline'),\n",
    "        FieldSpec('average', float, 'statistics_pipeline', frequency='per_study'),\n",
    "        FieldSpec('std_dev', float, 'statistics_pipeline',\n",
    "                  frequency='per_study')]\n",
    "    \n",
    "    add_param_specs = [\n",
    "        ParameterSpec('metric_of_interest', 'height')]\n",
    "    \n",
    "    def extract_metrics_pipeline(self, **name_maps):\n",
    "        pipeline = self.new_pipeline(\n",
    "            name='extract_metrics',\n",
    "            name_maps=name_maps,\n",
    "            desc=\"Extract metrics from file\")\n",
    "        \n",
    "        grep = pipeline.add(\n",
    "            'grep',\n",
    "            Grep(\n",
    "                match_str=self.parameter('metric_of_interest')),\n",
    "            inputs={\n",
    "                'in_file': ('body_metrics', text_format)})\n",
    "        \n",
    "        pipeline.add(\n",
    "            'awk',\n",
    "            Awk(\n",
    "                format_str='{print $2}'),\n",
    "            inputs={\n",
    "                'in_file': (grep, 'out_file')},\n",
    "            outputs={\n",
    "                'selected_metric': ('out_file', text_format)})\n",
    "        \n",
    "        return pipeline\n",
    "\n",
    "    def statistics_pipeline(self, **name_maps):\n",
    "        pipeline = self.new_pipeline(\n",
    "            name='statistics',\n",
    "            name_maps=name_maps,\n",
    "            desc=\"Calculate statistics\")\n",
    "        \n",
    "        merge_visits = pipeline.add(\n",
    "            'merge_visits',\n",
    "            Merge(\n",
    "                numinputs=1),\n",
    "            inputs={\n",
    "                'in1': ('selected_metric', text_format)})\n",
    "        \n",
    "        merge_subjects = pipeline.add(\n",
    "            'merge_subjects',\n",
    "            Merge(\n",
    "                numinputs=1,\n",
    "                ravel_inputs=True),\n",
    "            inputs={\n",
    "                'in1': (merge_visits, 'out')})\n",
    "        \n",
    "        concat = pipeline.add(\n",
    "            'concat',\n",
    "            ConcatFloats(),\n",
    "            inputs={\n",
    "                'in_files': (merge_subjects, 'out')})\n",
    "        \n",
    "        extract_metrics = pipeline.add(\n",
    "            'extract_metrics', \n",
    "            ExtractMetrics(),\n",
    "            inputs={\n",
    "                'in_list': (concat, 'out_list')},\n",
    "            outputs={\n",
    "                'average': ('avg', float),\n",
    "                'std_dev': ('std', float)})        \n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying MyStudy to test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from arcana import (\n",
    "    FilesetSelector, DirectoryRepository, LinearProcessor, StaticEnvironment)\n",
    "\n",
    "\n",
    "my_study = MyStudy(\n",
    "    name='example_mystudy',\n",
    "    repository=DirectoryRepository(project_dir, depth=2),\n",
    "    processor=LinearProcessor(work_dir=op.expanduser('~/work')),\n",
    "    environment=StaticEnvironment(),\n",
    "    inputs=[FilesetSelector('body_metrics', 'metrics', text_format)],\n",
    "    parameters={'metric_of_interest': 'height'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_study.data('average').value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_study.data('std_dev').value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Banana DwiStudy to example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banana.study.mri.dwi import DwiStudy\n",
    "from banana.file_format import dicom_format\n",
    "\n",
    "dwi_study = DwiStudy(\n",
    "    name='example_diffusion',\n",
    "    repository=DirectoryRepository(\n",
    "        op.join(op.expanduser('~'), 'Downloads', 'test-dir'), depth=0),\n",
    "    processor=LinearProcessor(work_dir=op.expanduser('~/work')),\n",
    "    environment=StaticEnvironment(),\n",
    "    inputs=[FilesetSelector('magnitude', 'R_L.*', dicom_format, is_regex=True),\n",
    "            FilesetSelector('reverse_phase', 'L_R.*', dicom_format,\n",
    "                            is_regex=True)],\n",
    "    parameters={'num_global_tracks': int(1e6)})\n",
    "\n",
    "\n",
    "# Generate whole brain tracks and return path to cached dataset\n",
    "wb_tcks = dwi_study.data('global_tracks')\n",
    "for sess_tcks in wb_tcks:\n",
    "    print(\"Performed whole-brain tractography for {}:{} session, the results \"\n",
    "          \"are stored at '{}'\"\n",
    "          .format(sess_tcks.subject_id, sess_tcks.visit_id, sess_tcks.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
