{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, math, os.path, shutil, errno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up dummy project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created project in /Users/tclose/Desktop/arcana_tutorial directory\n"
     ]
    }
   ],
   "source": [
    "# Create a test project with dummy data\n",
    "NUM_SUBJECTS = 3\n",
    "NUM_VISITS = 2\n",
    "\n",
    "HEIGHT_MEAN = 1700\n",
    "HEIGHT_STD = 150\n",
    "WEIGHT_MEAN = 70\n",
    "WEIGHT_STD = 25\n",
    "HEAD_CIRC_MEAN = 570\n",
    "HEAD_CIRC_STD = 30\n",
    "\n",
    "subjects = ['subject{}'.format(i) for i in range(NUM_SUBJECTS)]\n",
    "visits = ['visit{}'.format(i) for i in range(NUM_VISITS)]\n",
    "\n",
    "project_dir = os.path.join(os.environ['HOME'], 'Desktop', 'arcana_tutorial')\n",
    "# Clean old directory\n",
    "shutil.rmtree(project_dir, ignore_errors=True)\n",
    "os.mkdir(project_dir)\n",
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        session_dir = os.path.join(project_dir, subj, visit)\n",
    "        try:\n",
    "            os.makedirs(session_dir)\n",
    "        except OSError as e:\n",
    "            if e.errno != errno.EEXIST:\n",
    "                raise\n",
    "        with open(os.path.join(session_dir, 'metrics.txt'), 'w') as f:\n",
    "            f.write('height {}\\n'.format(numpy.random.randn() * HEIGHT_STD + HEIGHT_MEAN))\n",
    "            f.write('weight {}\\n'.format(numpy.random.randn() * WEIGHT_STD + WEIGHT_MEAN))\n",
    "            f.write('head_circ {}\\n'.format(numpy.random.randn() * HEAD_CIRC_STD + HEAD_CIRC_MEAN))\n",
    "print(\"Created project in {} directory\".format(project_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interface for 'grep' tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, File, isdefined,\n",
    "    CommandLineInputSpec, CommandLine)\n",
    "\n",
    "class GrepInputSpec(CommandLineInputSpec):\n",
    "    match_str = traits.Str(argstr='-e %s', position=0,\n",
    "                           desc=\"The string to search for\")\n",
    "    in_file = File(argstr='%s', position=1,\n",
    "                   desc=\"The file to search\")\n",
    "    out_file = File(genfile=True, argstr='> %s', position=2,\n",
    "                    desc=(\"The file to contain the search results\"))\n",
    "\n",
    "\n",
    "class GrepOutputSpec(TraitedSpec):\n",
    "    out_file = File(exists=True, desc=\"The search results\")\n",
    "\n",
    "\n",
    "class Grep(CommandLine):\n",
    "    \"\"\"Creates a zip archive from a given folder\"\"\"\n",
    "\n",
    "    _cmd = 'grep'\n",
    "    input_spec = GrepInputSpec\n",
    "    output_spec = GrepOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_file'] = self._gen_filename('out_file')\n",
    "        return outputs\n",
    "\n",
    "    def _gen_filename(self, name):\n",
    "        if name == 'out_file':\n",
    "            if isdefined(self.inputs.out_file):\n",
    "                fname = self.inputs.out_file\n",
    "            else:\n",
    "                fname = os.path.join(os.getcwd(), 'search_results.txt')\n",
    "        else:\n",
    "            assert False\n",
    "        return fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "out_file = /Users/tclose/Documents/Presentations/2019-02-04-Vector-Arcana-2/search_results.txt\n",
      "\n",
      "/Users/tclose/Documents/Presentations/2019-02-04-Vector-Arcana-2\n",
      "['MBI-Vector 2019-02-04.pptx', 'MBI-Vector-2019-02-04.ipynb', '.DS_Store', 'search_results.txt', '~$MBI-Vector 2019-02-04.pptx', 'graph.png', 'test-dir', 'my_workflow', '.ipynb_checkpoints', 'graph.dot', 'pyscript.m']\n"
     ]
    }
   ],
   "source": [
    "grep = Grep()\n",
    "grep.inputs.in_file = os.path.join(project_dir, 'subject0', 'visit0', 'metrics.txt')\n",
    "grep.inputs.match_str = 'height'\n",
    "results = grep.run()\n",
    "print(results.outputs)\n",
    "print(os.getcwd())\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject0/visit0/grep.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject0/visit1/grep.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject1/visit0/grep.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject1/visit1/grep.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject2/visit0/grep.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject2/visit1/grep.txt\n"
     ]
    }
   ],
   "source": [
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        grep = Grep()\n",
    "        grep.inputs.match_str = 'height'\n",
    "        grep.inputs.in_file = os.path.join(project_dir, subj, visit, 'metrics.txt')\n",
    "        grep.inputs.out_file = os.path.join(project_dir, subj, visit, 'grep.txt')\n",
    "        result = grep.run()\n",
    "        print('Processed {}'.format(result.outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create interface for 'awk' tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, File, isdefined,\n",
    "    CommandLineInputSpec, CommandLine)\n",
    "\n",
    "class AwkInputSpec(CommandLineInputSpec):\n",
    "    format_str = traits.Str(argstr=\"'%s'\", position=0,\n",
    "                            desc=\"The string to search for\")\n",
    "    in_file = File(argstr='%s', position=1,\n",
    "                   desc=\"The file to parse\")\n",
    "    out_file = File(genfile=True, argstr='> %s', position=2,\n",
    "                    desc=(\"The file to contain the parsed results\"))\n",
    "\n",
    "\n",
    "class AwkOutputSpec(TraitedSpec):\n",
    "    out_file = File(exists=True, desc=\"The parsed results\")\n",
    "\n",
    "\n",
    "class Awk(CommandLine):\n",
    "    \"\"\"Creates a zip archive from a given folder\"\"\"\n",
    "\n",
    "    _cmd = 'awk'\n",
    "    input_spec = AwkInputSpec\n",
    "    output_spec = AwkOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_file'] = self._gen_filename('out_file')\n",
    "        return outputs\n",
    "\n",
    "    def _gen_filename(self, name):\n",
    "        if name == 'out_file':\n",
    "            if isdefined(self.inputs.out_file):\n",
    "                fname = self.inputs.out_file\n",
    "            else:\n",
    "                fname = os.path.join(os.getcwd(), 'awk_results.txt')\n",
    "        else:\n",
    "            assert False\n",
    "        return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject0/visit0/awk.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject0/visit1/awk.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject1/visit0/awk.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject1/visit1/awk.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject2/visit0/awk.txt\n",
      "Processed /Users/tclose/Desktop/arcana_tutorial/subject2/visit1/awk.txt\n"
     ]
    }
   ],
   "source": [
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        awk = Awk()\n",
    "        awk.inputs.format_str = '{print $2}'\n",
    "        awk.inputs.in_file = os.path.join(project_dir, subj, visit, 'grep.txt')\n",
    "        awk.inputs.out_file = os.path.join(project_dir, subj, visit, 'awk.txt')\n",
    "        result = awk.run()\n",
    "        print('Processed {}'.format(result.outputs.out_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Matlab interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import traits\n",
    "from nipype.interfaces.base import TraitedSpec\n",
    "from nipype.interfaces.matlab import MatlabCommand, MatlabInputSpec\n",
    "\n",
    "\n",
    "class HelloWorldInputSpec(MatlabInputSpec):\n",
    "    name = traits.Str(mandatory=True,\n",
    "                      desc='Name of person to say hello to')\n",
    "\n",
    "\n",
    "class HelloWorldOutputSpec(TraitedSpec):\n",
    "    matlab_output = traits.Str()\n",
    "\n",
    "\n",
    "class HelloWorld(MatlabCommand):\n",
    "    input_spec = HelloWorldInputSpec\n",
    "    output_spec = HelloWorldOutputSpec\n",
    "\n",
    "    def _my_script(self):\n",
    "        \"\"\"This is where you implement your script\"\"\"\n",
    "        script = \"\"\"\n",
    "        disp('Hello {}')\n",
    "        \"\"\".format(self.inputs.name)\n",
    "        return script\n",
    "\n",
    "    def run(self, **inputs):\n",
    "        # Inject your script\n",
    "        self.inputs.script = self._my_script()\n",
    "        results = super(MatlabCommand, self).run(**inputs)\n",
    "        stdout = results.runtime.stdout\n",
    "        # Attach stdout to outputs to access matlab results\n",
    "        results.outputs.matlab_output = stdout\n",
    "        return results\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        outputs = self._outputs().get()\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                            < M A T L A B (R) >\n",
      "                  Copyright 1984-2018 The MathWorks, Inc.\n",
      "                   R2018a (9.4.0.813654) 64-bit (maci64)\n",
      "                             February 23, 2018\n",
      "\n",
      "[\bWarning: Name is nonexistent or not a directory:\n",
      "/Users/tclose/git/ni/sti/Support_Functions/NII/wavelet_src]\b \n",
      " \n",
      "To get started, type one of these: helpwin, helpdesk, or demo.\n",
      "For product information, visit www.mathworks.com.\n",
      " \n",
      "Executing pyscript at 04-Feb-2019 13:50:39:\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB Version: 9.4.0.813654 (R2018a)\n",
      "MATLAB License Number: 678256\n",
      "Operating System: Mac OS X  Version: 10.13.6 Build: 17G65 \n",
      "Java Version: Java 1.8.0_144-b01 with Oracle Corporation Java HotSpot(TM) 64-Bit Server VM mixed mode\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "MATLAB                                                Version 9.4         (R2018a)                \n",
      "Simulink                                              Version 9.1         (R2018a)                \n",
      "Control System Toolbox                                Version 10.4        (R2018a)                \n",
      "DSP System Toolbox                                    Version 9.6         (R2018a)                \n",
      "FieldTrip                                             Version unknown     www.fieldtriptoolbox.org\n",
      "Image Processing Toolbox                              Version 10.2        (R2018a)                \n",
      "MATLAB Compiler                                       Version 6.6         (R2018a)                \n",
      "MATLAB Compiler SDK                                   Version 6.5         (R2018a)                \n",
      "Neural Network Toolbox                                Version 11.1        (R2018a)                \n",
      "Optimization Toolbox                                  Version 8.1         (R2018a)                \n",
      "Parallel Computing Toolbox                            Version 6.12        (R2018a)                \n",
      "Signal Processing Toolbox                             Version 8.0         (R2018a)                \n",
      "Simulink Control Design                               Version 5.1         (R2018a)                \n",
      "Statistical Parametric Mapping                        Version 7219        (SPM12)                 \n",
      "Statistics and Machine Learning Toolbox               Version 11.3        (R2018a)                \n",
      "Symbolic Math Toolbox                                 Version 8.1         (R2018a)                \n",
      "Wavelet Toolbox                                       Version 5.0         (R2018a)                \n",
      "Yokogawa MEG Reader toolbox for MATLAB                Version 1.04.01                             \n",
      "Hello Tom\n"
     ]
    }
   ],
   "source": [
    "hello = HelloWorld()\n",
    "hello.inputs.name = 'Tom'\n",
    "out = hello.run()\n",
    "print(out.outputs.matlab_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility 'concat' Python interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, BaseInterface, File, isdefined, InputMultiPath)\n",
    "\n",
    "class ConcatFloatsInputSpec(TraitedSpec):\n",
    "    in_files = InputMultiPath(desc='file name')\n",
    "\n",
    "\n",
    "class ConcatFloatsOutputSpec(TraitedSpec):\n",
    "    out_list = traits.List(traits.Float, desc='input floats')\n",
    "\n",
    "\n",
    "class ConcatFloats(BaseInterface):\n",
    "    \"\"\"Joins values from a list of files into a single list\"\"\"\n",
    "\n",
    "    input_spec = ConcatFloatsInputSpec\n",
    "    output_spec = ConcatFloatsOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        out_list = []\n",
    "        for path in self.inputs.in_files:\n",
    "            with open(path) as f:\n",
    "                val = float(f.read())\n",
    "                out_list.append(val)\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['out_list'] = out_list\n",
    "        return outputs\n",
    "\n",
    "    def _run_interface(self, runtime):\n",
    "        # Do nothing\n",
    "        return runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python interface using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces.base import (\n",
    "    TraitedSpec, traits, BaseInterface)\n",
    "\n",
    "class ExtractMetricsInputSpec(TraitedSpec):\n",
    "    in_list = traits.List(traits.Float, desc='input floats')\n",
    "\n",
    "\n",
    "class ExtractMetricsOutputSpec(TraitedSpec):\n",
    "    std = traits.Float(desc=\"The standard deviation\")\n",
    "    avg = traits.Float(desc=\"The average\")\n",
    "\n",
    "\n",
    "class ExtractMetrics(BaseInterface):\n",
    "    \"\"\"Joins values from a list of files into a single list\"\"\"\n",
    "\n",
    "    input_spec = ExtractMetricsInputSpec\n",
    "    output_spec = ExtractMetricsOutputSpec\n",
    "\n",
    "    def _list_outputs(self):\n",
    "        values = self.inputs.in_list\n",
    "        outputs = self._outputs().get()\n",
    "        outputs['std'] = numpy.std(values)\n",
    "        outputs['avg'] = numpy.average(values)\n",
    "        return outputs\n",
    "\n",
    "    def _run_interface(self, runtime):\n",
    "        # Do nothing\n",
    "        return runtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual run concatenation and metric extraction over project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output list [1865.3997988028266, 1654.1872032510767, 1925.8241108822733, 1848.7633659299897, 1727.017752746845, 1777.1652630024328]\n",
      "Average: 1799.726249102574\n",
      "Std.: 90.91705203634373\n"
     ]
    }
   ],
   "source": [
    "in_files = []\n",
    "for subj in subjects:\n",
    "    for visit in visits:\n",
    "        in_files.append(os.path.join(project_dir, subj, visit, 'awk.txt'))\n",
    "\n",
    "concat_floats = ConcatFloats()\n",
    "concat_floats.inputs.in_files = in_files\n",
    "result = concat_floats.run()\n",
    "print('Output list {}'.format(result.outputs.out_list))\n",
    "\n",
    "extract_metrics = ExtractMetrics()\n",
    "extract_metrics.inputs.in_list = result.outputs.out_list\n",
    "result = extract_metrics.run()\n",
    "print('Average: {}'.format(result.outputs.avg))\n",
    "print('Std.: {}'.format(result.outputs.std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NiPype workflow for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190204-13:50:44,903 nipype.workflow INFO:\n",
      "\t Workflow my_workflow settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "190204-13:50:44,933 nipype.workflow INFO:\n",
      "\t Running serially.\n",
      "190204-13:50:44,934 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmpm3cjtm10/my_workflow/_subject_id_subject2/_visit_id_visit1/datasource\".\n",
      "190204-13:50:44,939 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:44,947 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:44,948 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmp6jxx_46u/my_workflow/_subject_id_subject2/_visit_id_visit1/grep\".\n",
      "190204-13:50:44,953 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject2/visit1/metrics.txt > /private/tmp/tmp6jxx_46u/my_workflow/_subject_id_subject2/_visit_id_visit1/grep/search_results.txt\n",
      "190204-13:50:45,27 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,29 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmp25j6n147/my_workflow/_subject_id_subject2/_visit_id_visit1/awk\".\n",
      "190204-13:50:45,38 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmp6jxx_46u/my_workflow/_subject_id_subject2/_visit_id_visit1/grep/search_results.txt > /private/tmp/tmp25j6n147/my_workflow/_subject_id_subject2/_visit_id_visit1/awk/awk_results.txt\n",
      "190204-13:50:45,117 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:45,119 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmp3mp63toc/my_workflow/_subject_id_subject1/_visit_id_visit1/datasource\".\n",
      "190204-13:50:45,125 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:45,133 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:45,135 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmp9r3rcoeu/my_workflow/_subject_id_subject1/_visit_id_visit1/grep\".\n",
      "190204-13:50:45,141 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject1/visit1/metrics.txt > /private/tmp/tmp9r3rcoeu/my_workflow/_subject_id_subject1/_visit_id_visit1/grep/search_results.txt\n",
      "190204-13:50:45,215 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,216 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmp5as6x76p/my_workflow/_subject_id_subject1/_visit_id_visit1/awk\".\n",
      "190204-13:50:45,224 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmp9r3rcoeu/my_workflow/_subject_id_subject1/_visit_id_visit1/grep/search_results.txt > /private/tmp/tmp5as6x76p/my_workflow/_subject_id_subject1/_visit_id_visit1/awk/awk_results.txt\n",
      "190204-13:50:45,299 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:45,301 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmp_5opfjdg/my_workflow/_subject_id_subject0/_visit_id_visit1/datasource\".\n",
      "190204-13:50:45,307 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:45,314 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:45,315 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmp18tdhu02/my_workflow/_subject_id_subject0/_visit_id_visit1/grep\".\n",
      "190204-13:50:45,322 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject0/visit1/metrics.txt > /private/tmp/tmp18tdhu02/my_workflow/_subject_id_subject0/_visit_id_visit1/grep/search_results.txt\n",
      "190204-13:50:45,396 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,397 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmpjhbdyqt9/my_workflow/_subject_id_subject0/_visit_id_visit1/awk\".\n",
      "190204-13:50:45,404 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmp18tdhu02/my_workflow/_subject_id_subject0/_visit_id_visit1/grep/search_results.txt > /private/tmp/tmpjhbdyqt9/my_workflow/_subject_id_subject0/_visit_id_visit1/awk/awk_results.txt\n",
      "190204-13:50:45,479 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:45,481 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmpi1jspqs2/my_workflow/_subject_id_subject2/_visit_id_visit0/datasource\".\n",
      "190204-13:50:45,487 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:45,493 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:45,495 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmpz57yjaf8/my_workflow/_subject_id_subject2/_visit_id_visit0/grep\".\n",
      "190204-13:50:45,501 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject2/visit0/metrics.txt > /private/tmp/tmpz57yjaf8/my_workflow/_subject_id_subject2/_visit_id_visit0/grep/search_results.txt\n",
      "190204-13:50:45,575 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,577 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmp9iadrej8/my_workflow/_subject_id_subject2/_visit_id_visit0/awk\".\n",
      "190204-13:50:45,583 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmpz57yjaf8/my_workflow/_subject_id_subject2/_visit_id_visit0/grep/search_results.txt > /private/tmp/tmp9iadrej8/my_workflow/_subject_id_subject2/_visit_id_visit0/awk/awk_results.txt\n",
      "190204-13:50:45,657 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:45,658 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.merge_visits\" in \"/private/tmp/tmpo0kp8nqj/my_workflow/_subject_id_subject2/merge_visits\".\n",
      "190204-13:50:45,665 nipype.workflow INFO:\n",
      "\t [Node] Running \"merge_visits\" (\"nipype.interfaces.utility.base.Merge\")\n",
      "190204-13:50:45,672 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.merge_visits\".\n",
      "190204-13:50:45,673 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmpy6ppqm7z/my_workflow/_subject_id_subject1/_visit_id_visit0/datasource\".\n",
      "190204-13:50:45,680 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:45,686 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:45,687 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmp50mcbanx/my_workflow/_subject_id_subject1/_visit_id_visit0/grep\".\n",
      "190204-13:50:45,693 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject1/visit0/metrics.txt > /private/tmp/tmp50mcbanx/my_workflow/_subject_id_subject1/_visit_id_visit0/grep/search_results.txt\n",
      "190204-13:50:45,764 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,765 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmps19uuppd/my_workflow/_subject_id_subject1/_visit_id_visit0/awk\".\n",
      "190204-13:50:45,771 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmp50mcbanx/my_workflow/_subject_id_subject1/_visit_id_visit0/grep/search_results.txt > /private/tmp/tmps19uuppd/my_workflow/_subject_id_subject1/_visit_id_visit0/awk/awk_results.txt\n",
      "190204-13:50:45,847 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:45,849 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.merge_visits\" in \"/private/tmp/tmp_8exn9gh/my_workflow/_subject_id_subject1/merge_visits\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190204-13:50:45,856 nipype.workflow INFO:\n",
      "\t [Node] Running \"merge_visits\" (\"nipype.interfaces.utility.base.Merge\")\n",
      "190204-13:50:45,864 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.merge_visits\".\n",
      "190204-13:50:45,865 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.datasource\" in \"/private/tmp/tmp7ebjpw79/my_workflow/_subject_id_subject0/_visit_id_visit0/datasource\".\n",
      "190204-13:50:45,872 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasource\" (\"nipype.interfaces.io.DataGrabber\")\n",
      "190204-13:50:45,879 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.datasource\".\n",
      "190204-13:50:45,880 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.grep\" in \"/private/tmp/tmpa63cx6kx/my_workflow/_subject_id_subject0/_visit_id_visit0/grep\".\n",
      "190204-13:50:45,887 nipype.workflow INFO:\n",
      "\t [Node] Running \"grep\" (\"__main__.Grep\"), a CommandLine Interface with command:\n",
      "grep -e height /Users/tclose/Desktop/arcana_tutorial/subject0/visit0/metrics.txt > /private/tmp/tmpa63cx6kx/my_workflow/_subject_id_subject0/_visit_id_visit0/grep/search_results.txt\n",
      "190204-13:50:45,970 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.grep\".\n",
      "190204-13:50:45,971 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.awk\" in \"/private/tmp/tmp5xyjai17/my_workflow/_subject_id_subject0/_visit_id_visit0/awk\".\n",
      "190204-13:50:45,980 nipype.workflow INFO:\n",
      "\t [Node] Running \"awk\" (\"__main__.Awk\"), a CommandLine Interface with command:\n",
      "awk '{print $2}' /private/tmp/tmpa63cx6kx/my_workflow/_subject_id_subject0/_visit_id_visit0/grep/search_results.txt > /private/tmp/tmp5xyjai17/my_workflow/_subject_id_subject0/_visit_id_visit0/awk/awk_results.txt\n",
      "190204-13:50:46,59 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.awk\".\n",
      "190204-13:50:46,61 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.merge_visits\" in \"/private/tmp/tmpw1enzvoc/my_workflow/_subject_id_subject0/merge_visits\".\n",
      "190204-13:50:46,69 nipype.workflow INFO:\n",
      "\t [Node] Running \"merge_visits\" (\"nipype.interfaces.utility.base.Merge\")\n",
      "190204-13:50:46,77 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.merge_visits\".\n",
      "190204-13:50:46,79 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.merge_subjects\" in \"/private/tmp/tmpb9a3ut93/my_workflow/merge_subjects\".\n",
      "190204-13:50:46,87 nipype.workflow INFO:\n",
      "\t [Node] Running \"merge_subjects\" (\"nipype.interfaces.utility.base.Merge\")\n",
      "190204-13:50:46,94 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.merge_subjects\".\n",
      "190204-13:50:46,96 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.concat\" in \"/private/tmp/tmpuo3o___q/my_workflow/concat\".\n",
      "190204-13:50:46,103 nipype.workflow INFO:\n",
      "\t [Node] Running \"concat\" (\"__main__.ConcatFloats\")\n",
      "190204-13:50:46,112 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.concat\".\n",
      "190204-13:50:46,113 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"my_workflow.extract\" in \"/private/tmp/tmpmt5fqnf0/my_workflow/extract\".\n",
      "190204-13:50:46,120 nipype.workflow INFO:\n",
      "\t [Node] Running \"extract\" (\"__main__.ExtractMetrics\")\n",
      "190204-13:50:46,128 nipype.workflow INFO:\n",
      "\t [Node] Finished \"my_workflow.extract\".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x117dc9f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nipype.pipeline import engine as pe  # pypeline engine\n",
    "from nipype.interfaces.utility import IdentityInterface, Merge\n",
    "from nipype.interfaces.io import DataGrabber\n",
    "\n",
    "# Create workflow\n",
    "workflow = pe.Workflow(name='my_workflow')\n",
    "\n",
    "# Create subjects iterator\n",
    "subject_iterator = pe.Node(IdentityInterface(['subject_id']),\n",
    "                           name='subject_iterator')\n",
    "workflow.add_nodes([subject_iterator])\n",
    "subject_iterator.iterables = ('subject_id', subjects)\n",
    "\n",
    "# Create visits iterator\n",
    "visit_iterator = pe.Node(IdentityInterface(['visit_id']),\n",
    "                         name='visit_iterator')\n",
    "workflow.add_nodes([visit_iterator])\n",
    "visit_iterator.iterables = ('visit_id', visits)\n",
    "\n",
    "# Create data grabber\n",
    "datasource = pe.Node(\n",
    "    interface=DataGrabber(\n",
    "        infields=['subject_id', 'visit_id'], outfields=['metrics']),\n",
    "    name='datasource')\n",
    "datasource.inputs.template = \"%s/%s/metrics.txt\"\n",
    "datasource.inputs.base_directory = project_dir\n",
    "datasource.inputs.sort_filelist = True\n",
    "datasource.inputs.template_args = {'metrics': [['subject_id', 'visit_id']]}\n",
    "workflow.add_nodes([datasource])\n",
    "\n",
    "# Create grep node\n",
    "grep = pe.Node(Grep(), name='grep')\n",
    "grep.inputs.match_str = 'height'\n",
    "workflow.add_nodes([grep])\n",
    "\n",
    "# Create awk node\n",
    "awk = pe.Node(Awk(), name='awk')\n",
    "awk.inputs.format_str = '{print $2}'\n",
    "workflow.add_nodes([awk])\n",
    "\n",
    "# Merge subject and visit iterators\n",
    "merge_visits = pe.JoinNode(Merge(1), name='merge_visits', joinfield='in1',\n",
    "                           joinsource='visit_iterator')\n",
    "merge_subjects = pe.JoinNode(Merge(1), name='merge_subjects', joinfield='in1',\n",
    "                    joinsource='subject_iterator')\n",
    "merge_subjects.inputs.ravel_inputs = True\n",
    "workflow.add_nodes([merge_subjects, merge_visits])\n",
    "                                            \n",
    "# Concat floats node\n",
    "concat = pe.Node(ConcatFloats(), name='concat')\n",
    "workflow.add_nodes([concat])\n",
    "                                            \n",
    "# Extract metrics Node\n",
    "extract_metrics = pe.Node(ExtractMetrics(), name='extract')\n",
    "workflow.add_nodes([extract_metrics])\n",
    "                                            \n",
    "# Connect Nodes together                          \n",
    "workflow.connect(subject_iterator, 'subject_id', datasource, 'subject_id')\n",
    "workflow.connect(visit_iterator, 'visit_id', datasource, 'visit_id')\n",
    "workflow.connect(datasource, 'metrics', grep, 'in_file')\n",
    "workflow.connect(grep, 'out_file', awk, 'in_file')\n",
    "workflow.connect(awk, 'out_file', merge_visits, 'in1')\n",
    "workflow.connect(merge_visits, 'out', merge_subjects, 'in1')\n",
    "workflow.connect(merge_subjects, 'out', concat, 'in_files')\n",
    "workflow.connect(concat, 'out_list', extract_metrics, 'in_list')\n",
    "             \n",
    "\n",
    "# Run workflow\n",
    "workflow.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190204-13:50:46,293 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /Users/tclose/Documents/Presentations/2019-02-04-Vector-Arcana-2/graph.png (graph2use=hierarchical, simple_form=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/tclose/Documents/Presentations/2019-02-04-Vector-Arcana-2/graph.png'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.write_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('graph.png')\n",
    "fig = plt.figure()\n",
    "plt.imshow(img)\n",
    "fig.set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Arcana Study class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Study class, defining its constituent data and option specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcana\n",
    "from arcana import (Study, StudyMetaClass, ParameterSpec, AcquiredFilesetSpec,\n",
    "                    FilesetSpec, FieldSpec)\n",
    "from arcana.data.file_format.standard import text_format\n",
    "\n",
    "\n",
    "class MyStudy(Study, metaclass=StudyMetaClass): \n",
    "    \n",
    "    add_data_specs = [\n",
    "        AcquiredFilesetSpec('body_metrics', text_format),\n",
    "        FilesetSpec('selected_metric', text_format, 'extract_metrics_pipeline'),\n",
    "        FieldSpec('average', float, 'statistics_pipeline', frequency='per_study'),\n",
    "        FieldSpec('std_dev', float, 'statistics_pipeline',\n",
    "                  frequency='per_study')]\n",
    "    \n",
    "    add_param_specs = [\n",
    "        ParameterSpec('metric_of_interest', 'height')]\n",
    "    \n",
    "    def extract_metrics_pipeline(self, **name_maps):\n",
    "        pipeline = self.new_pipeline(\n",
    "            name='extract_metrics',\n",
    "            name_maps=name_maps,\n",
    "            desc=\"Extract metrics from file\")\n",
    "        \n",
    "        grep = pipeline.add(\n",
    "            'grep',\n",
    "            Grep(\n",
    "                match_str=self.parameter('metric_of_interest')),\n",
    "            inputs={\n",
    "                'in_file': ('body_metrics', text_format)})\n",
    "        \n",
    "        pipeline.add(\n",
    "            'awk',\n",
    "            Awk(\n",
    "                format_str='{print $2}'),\n",
    "            inputs={\n",
    "                'in_file': (grep, 'out_file')},\n",
    "            outputs={\n",
    "                'selected_metric': ('out_file', text_format)})\n",
    "        \n",
    "        return pipeline\n",
    "\n",
    "    def statistics_pipeline(self, **name_maps):\n",
    "        pipeline = self.new_pipeline(\n",
    "            name='statistics',\n",
    "            name_maps=name_maps,\n",
    "            desc=\"Calculate statistics\")\n",
    "        \n",
    "        merge_visits = pipeline.add(\n",
    "            'merge_visits',\n",
    "            Merge(\n",
    "                numinputs=1),\n",
    "            inputs={\n",
    "                'in1': ('selected_metric', text_format)})\n",
    "        \n",
    "        merge_subjects = pipeline.add(\n",
    "            'merge_subjects',\n",
    "            Merge(\n",
    "                numinputs=1,\n",
    "                ravel_inputs=True),\n",
    "            inputs={\n",
    "                'in1': (merge_visits, 'out')})\n",
    "        \n",
    "        concat = pipeline.add(\n",
    "            'concat',\n",
    "            ConcatFloats(),\n",
    "            inputs={\n",
    "                'in_files': (merge_subjects, 'out')})\n",
    "        \n",
    "        extract_metrics = pipeline.add(\n",
    "            'extract_metrics', \n",
    "            ExtractMetrics(),\n",
    "            inputs={\n",
    "                'in_list': (concat, 'out_list')},\n",
    "            outputs={\n",
    "                'average': ('avg', float),\n",
    "                'std_dev': ('std', float)})        \n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying MyStudy to test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from arcana import (\n",
    "    FilesetSelector, DirectoryRepository, LinearProcessor, StaticEnvironment)\n",
    "\n",
    "\n",
    "my_study = MyStudy(\n",
    "    name='example_mystudy',\n",
    "    repository=DirectoryRepository(project_dir, depth=2),\n",
    "    processor=LinearProcessor(work_dir=op.expanduser('~/work')),\n",
    "    environment=StaticEnvironment(),\n",
    "    inputs=[FilesetSelector('body_metrics', 'metrics', text_format)],\n",
    "    parameters={'metric_of_interest': 'height'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Banana DwiStudy to example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tclose/git/ni/banana/banana/interfaces/custom/dicom.py:13: UserWarning: The DICOM readers are highly experimental, unstable, and only work for Siemens time-series at the moment\n",
      "Please use with caution.  We would be grateful for your help in improving them\n",
      "  import nibabel.nicom.csareader as csareader\n",
      "/Users/tclose/git/ni/banana/banana/interfaces/custom/motion_correction.py:15: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 497, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 132, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 539, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py\", line 1775, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n",
      "    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/usr/local/Cellar/python/3.7.2_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dicom_format' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4a2ca07f0e79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprocessor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwork_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/work'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStaticEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     inputs=[FilesetSelector('magnitude', 'R_L.*', dicom_format, is_regex=True),\n\u001b[0m\u001b[1;32m     10\u001b[0m             FilesetSelector('reverse_phase', 'L_R.*', dicom_format,\n\u001b[1;32m     11\u001b[0m                             is_regex=True)],\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dicom_format' is not defined"
     ]
    }
   ],
   "source": [
    "from banana.study.mri.dwi import DwiStudy\n",
    "\n",
    "dwi_study = DwiStudy(\n",
    "    name='example_diffusion',\n",
    "    repository=DirectoryRepository(\n",
    "        op.join(op.expanduser('~'), 'Downloads', 'test-dir'), depth=0),\n",
    "    processor=LinearProcessor(work_dir=op.expanduser('~/work')),\n",
    "    environment=StaticEnvironment(),\n",
    "    inputs=[FilesetSelector('magnitude', 'R_L.*', dicom_format, is_regex=True),\n",
    "            FilesetSelector('reverse_phase', 'L_R.*', dicom_format,\n",
    "                            is_regex=True)],\n",
    "    parameters={'num_global_tracks': int(1e6)})\n",
    "\n",
    "\n",
    "# Generate whole brain tracks and return path to cached dataset\n",
    "wb_tcks = study.data('global_tracks')\n",
    "for sess_tcks in wb_tcks:\n",
    "    print(\"Performed whole-brain tractography for {}:{} session, the results \"\n",
    "          \"are stored at '{}'\"\n",
    "          .format(sess_tcks.subject_id, sess_tcks.visit_id, sess_tcks.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
